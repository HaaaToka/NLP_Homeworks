{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynet as dy\n",
    "import json\n",
    "from glove import Glove\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import random\n",
    "\n",
    "\n",
    "def DefaultdictInside():\n",
    "    return [defaultdict(int),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorDim = 50 # 50 100 200 300\n",
    "ngram = 2 # 3->trigram   2->bigram  1->unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...\n",
      "Just Finished Reading dataset...\n",
      "Poem Count: 100\n",
      "Unique Gram: 1361\n",
      "Total Word: 5223\n"
     ]
    }
   ],
   "source": [
    "# bos # begin of sentence\n",
    "# eos # end of sentence\n",
    "# eol # end of line\n",
    "# bol # begin of line\n",
    "\n",
    "def read_dataset(fpath):\n",
    "    print(\"Reading dataset...\")\n",
    "    poems=[]\n",
    "    n_grams_dict=defaultdict(DefaultdictInside)\n",
    "    with open(fpath) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for d in data:\n",
    "            if d[\"id\"]==100:\n",
    "                break\n",
    "            poem = d[\"poem\"]\n",
    "            poem = poem.replace(\"\\n\",\" eol bol \")\n",
    "            #poem = poem.lower() -- dataset already lowercased\n",
    "            #poem = poem.replace(\"\\n\",\" eol \")\n",
    "            poem = poem.replace(\".\",\" \")\n",
    "            poem = poem.replace(\":\",\" \")\n",
    "            poem = poem.replace(\"?\",\" \")\n",
    "            poem = \"bos bol \"+poem+\" eol eos\"\n",
    "            #poem = \"bos \"+poem+\" eos\"\n",
    "            poem = poem.split()\n",
    "            poems.append([])\n",
    "            for i in range(len(poem)-ngram+1):\n",
    "                poems[-1].append(poem[i:i+ngram])\n",
    "                \n",
    "                prev_gram = poems[-1][-1][:ngram-1]\n",
    "                next_gram = poems[-1][-1][-1]    \n",
    "                n_grams_dict[\" \".join(prev_gram)][1]+=1\n",
    "                n_grams_dict[\" \".join(prev_gram)][0][next_gram]+=1\n",
    "            n_grams_dict[\"eos\"][1]+=1\n",
    "            \n",
    "    print(\"Just Finished Reading dataset...\")\n",
    "    return poems,n_grams_dict\n",
    "\n",
    "poems,count_dict= read_dataset('unim_poem.json')\n",
    "print(\"Poem Count:\",len(poems))\n",
    "#print(poems[0])\n",
    "keys = list(count_dict.keys())\n",
    "unique_gram = len(keys)\n",
    "print(\"Unique Gram:\",unique_gram)\n",
    "tot=0\n",
    "for k,v in count_dict.items():\n",
    "    tot += v[1]\n",
    "print(\"Total Word:\",tot)\n",
    "\n",
    "# replace(\".:?\",\" \")\n",
    "# , ; ! \" | yok\n",
    "# ' - 're 's n't 've 'll ellemedim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Finished Loading word vectors...\n",
      "(400001, 50)\n",
      "20000050\n"
     ]
    }
   ],
   "source": [
    "def read_glove(fpath):\n",
    "    print('Loading word vectors...')\n",
    "    word2vec = {}\n",
    "    embeds = []\n",
    "    word2idx = {}\n",
    "    with open(fpath, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            word2idx[word] = len(embeds)\n",
    "            vec = np.asarray(values[1:], dtype='float32')\n",
    "            word2vec[word] = vec\n",
    "            embeds.append(vec)\n",
    "            \n",
    "    mean = np.array(embeds).mean(axis=0,dtype='float32')\n",
    "    word2vec[\"mmeann\"]=mean\n",
    "    embeds.append(mean)\n",
    "    \n",
    "    print(\"Finished Loading word vectors...\")\n",
    "    return np.array(embeds),word2idx,word2vec\n",
    "\n",
    "embedding,w2i, w2v= read_glove('glovo/glove.6B.'+str(vectorDim)+'d.txt')\n",
    "#w2v[\"mmeann\"]=embedding.mean(axis=0) # if the word doesn't occur in vocab, it will take mean value\n",
    "print(embedding.shape)\n",
    "print(embedding.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. loss = 369.670079\n",
      "Epoch 2. loss = 365.700067\n",
      "Epoch 3. loss = 358.593593\n",
      "Epoch 4. loss = 358.499232\n",
      "Epoch 5. loss = 358.331282\n",
      "Epoch 6. loss = 358.258912\n",
      "Epoch 7. loss = 358.244593\n",
      "Epoch 8. loss = 358.243319\n",
      "Epoch 9. loss = 358.242166\n",
      "Epoch 10. loss = 358.237965\n"
     ]
    }
   ],
   "source": [
    "def sumvec(w2v,words):\n",
    "    \"\"\"\n",
    "        If our model was 3,4,5gram, \n",
    "        this function would add the value of the w2vs for input vector\n",
    "    \"\"\"\n",
    "    _temp = np.zeros(50)\n",
    "    for w in words:\n",
    "        try:\n",
    "            _temp+=w2v[w]\n",
    "        except:\n",
    "            _temp+=w2v[\"mmeann\"]\n",
    "    return _temp\n",
    "\n",
    "\n",
    "\n",
    "h = 150 # HiddenUnit\n",
    "m = vectorDim\n",
    "\n",
    "EPOCH = 10\n",
    "\n",
    "H = _model.add_parameters((h, m))\n",
    "d = _model.add_parameters(h)\n",
    "U = _model.add_parameters((unique_gram, h))\n",
    "b = _model.add_parameters(unique_gram)\n",
    "_trainer = dy.SimpleSGDTrainer(_model)\n",
    "\n",
    "\n",
    "i=0\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    epoch_loss = 0.0\n",
    "    for p in poems:\n",
    "        for gram in p:\n",
    "            x=sumvec(w2v,gram[:ngram-1])\n",
    "            try:\n",
    "                y=keys.index(gram[-1])\n",
    "            except:\n",
    "                y=random.randint(0,len(keys)-1)\n",
    "            dy.renew_cg()\n",
    "            x = dy.inputVector(x)\n",
    "            input_layer = dy.tanh(H * x + d)\n",
    "            hidden_layer = U * input_layer + b\n",
    "            output_layer = dy.softmax(hidden_layer)\n",
    "            loss = dy.pickneglogsoftmax(output_layer, y)\n",
    "            epoch_loss += loss.scalar_value()\n",
    "            loss.forward()\n",
    "            loss.backward()\n",
    "            _trainer.update()\n",
    "    print(\"Epoch %d. loss = %f\" % (epoch, epoch_loss/len(poems)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I leave you alone with my meaningless, absurd poems\n",
    "\n",
    "# def ganchart(possiblities):\n",
    "#     possiblities=sorted(possiblities,reverse=False)\n",
    "#     _sum = sum(possiblities)\n",
    "#     _len = len(possiblities)\n",
    "#     print(\"SUM:\",_sum)\n",
    "#     print(\"LEN:\",_len)\n",
    "   \n",
    "#     ind=-1\n",
    "#     rnd = random.uniform(0.0, _sum)\n",
    "#     print(\"\\tRAND:\",rnd)\n",
    "#     curTot = 0.0\n",
    "#     for i in range(_len):\n",
    "#         curTot+=possiblities[i]\n",
    "#         if curTot >= rnd:\n",
    "#             ind=i\n",
    "#             break\n",
    "#     print(\"\\t\\tINDEX:\",ind)\n",
    "#     return ind\n",
    "\n",
    "\n",
    "close=20#int(unique_gram/100*2)\n",
    "satir = 2\n",
    "_tempPoem=[]\n",
    "generated_poems=[]\n",
    "poemCount=20\n",
    "\n",
    "for _ in range(poemCount):\n",
    "    generated_poems.append([])\n",
    "    _tempPoem=[\"bos\"]\n",
    "    for i in range(satir):\n",
    "        #while 1:\n",
    "        while len(_tempPoem)<10:\n",
    "            x=sumvec(w2v,_tempPoem[-1])\n",
    "            dy.renew_cg()\n",
    "            x = dy.inputVector(x)\n",
    "            input_layer = dy.tanh(H * x + d)\n",
    "            hidden_layer = U * input_layer + b\n",
    "            output_layer = list(dy.softmax(hidden_layer).value())\n",
    "            oen = list(enumerate(output_layer))\n",
    "            oen=sorted(oen,key=itemgetter(1),reverse=True)\n",
    "            rnd = random.randint(0,close-1)\n",
    "            _tempPoem.append(keys[oen[rnd][0]])\n",
    "            #print(_tempPoem)\n",
    "            if _tempPoem[-1]==\"eol\":\n",
    "                break\n",
    "        generated_poems[-1]+=(_tempPoem)\n",
    "        _tempPoem=[\"eol\"]\n",
    "        #print()\n",
    "\n",
    "    \n",
    "    generated_poems[-1]= \" \".join(generated_poems[-1]).replace(\"bos \",\"\").replace(\"eol \",\"\\n\").replace(\"eol\",\"\").replace(\"bol \", \"\")\n",
    "    \n",
    "    #print(generated_poems[-1],\"\\n##############\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the adjusted we heaven rarely another adjusted lime adjusted \n",
      "adjusted pass moon sheet delight water baby delight we\n",
      "\t-> Perplexity of poem :324.35789555745333245795\n",
      "########################\n",
      "woman's we adjusted that coin \n",
      "\n",
      "sheet moonlight have \n",
      "\t-> Perplexity of poem :51.49990014837545260207\n",
      "########################\n",
      "rarely staring seems freight rarely life woman's up silver \n",
      "lot has its shrouded moon lot at north\n",
      "\t-> Perplexity of poem :298.79221078498949282221\n",
      "########################\n",
      "came been blue woman's if rarely undone undone \n",
      "\n",
      "saw rarely sin resonant staring stretch frail slabs frail\n",
      "\t-> Perplexity of poem :298.27598553501053402215\n",
      "########################\n",
      "missing' \n",
      "\n",
      "has its life my share undone we me\n",
      "\t-> Perplexity of poem :93.25408392245103073037\n",
      "########################\n",
      "came big share law law another sheet adjusted sin \n",
      "doesn't adjusted how reck sails the love deja\n",
      "\t-> Perplexity of poem :283.72760059364611606725\n",
      "########################\n",
      "came freight water staring rarely can't sweetness adjusted life \n",
      "bribe tho' uncontrolled frail wait north sheet frail \n",
      "\t-> Perplexity of poem :224.27258335807002254114\n",
      "########################\n",
      "been sails shall rarely sails darkness darkness law staring \n",
      "views if \n",
      "\t-> Perplexity of poem :103.57071998490434339146\n",
      "########################\n",
      "missing' tho' if if don't shall undone milne life \n",
      "the staring have we me share darkness up the\n",
      "\t-> Perplexity of poem :307.99633632874639488364\n",
      "########################\n",
      "deja north suit up moon big at life \n",
      "\n",
      "\t-> Perplexity of poem :98.95286307713708140454\n",
      "########################\n",
      "sweetness law the rarely sin don't stretch cause the \n",
      "undone baby preaching uncontrolled frail \n",
      "\t-> Perplexity of poem :164.47449879915768633509\n",
      "########################\n",
      "has ascending \n",
      "\n",
      "sheet frail share we adjusted \n",
      "\t-> Perplexity of poem :36.99397385018765049836\n",
      "########################\n",
      "rule me big adjusted \n",
      "\n",
      "up beside patiently \n",
      "\t-> Perplexity of poem :36.99427219711688508141\n",
      "########################\n",
      "woman's share pass rarely baby we blue moonlight \n",
      "\n",
      "if seems came has ascending rarely law share \n",
      "\t-> Perplexity of poem :204.25689219378853067610\n",
      "########################\n",
      "undone uncontrolled rule sails seems been \n",
      "\n",
      "been sails shrouded rule another adjusted adjusted has another\n",
      "\t-> Perplexity of poem :249.42991892270657672270\n",
      "########################\n",
      "rule murmur freight me if don't \n",
      "\n",
      "been milne shall staring tho' if have milne at\n",
      "\t-> Perplexity of poem :250.20047638062800388070\n",
      "########################\n",
      "frail adjusted we sent o'duffy the nightingale seems big \n",
      "thebaid sweetness sails staring o shall woman's staring tho'\n",
      "\t-> Perplexity of poem :313.40063245082126286434\n",
      "########################\n",
      "creator delight kind tone me adjusted sin delight moonlight \n",
      "= adjusted coin staring have freight up my slabs\n",
      "\t-> Perplexity of poem :311.69332573640571126816\n",
      "########################\n",
      "has another freight don't fool missing' rarely pass law \n",
      "\n",
      "\t-> Perplexity of poem :122.93167158603021960062\n",
      "########################\n",
      "creator rarely sails shrouded missing' at cemeteries staring o \n",
      "lot \n",
      "\t-> Perplexity of poem :84.95951173885949003761\n",
      "########################\n"
     ]
    }
   ],
   "source": [
    "def Sprob(poem,n_grams_dict,unique_word,ngram):\n",
    "    # Returns the MLE of given sentence with laplace smoothing\n",
    "        \n",
    "    result = 1\n",
    "    split_poem = poem.split()+[\"eol\"]\n",
    "\n",
    "\n",
    "    for index in range(len(split_poem)-ngram):\n",
    "        prev_gram = \" \".join(split_poem[index:ngram+index-1])\n",
    "        next_gram = split_poem[ngram+index-1]\n",
    "\n",
    "        result *= ( (n_grams_dict[prev_gram][0][next_gram] + 1) / (n_grams_dict[prev_gram][1] + unique_word) )\n",
    "\n",
    "    #print(\"\\t-> S-Probabilty of sentence :{0:.30f}\".format(result))\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def perplexity(poems,n_grams_dict,unique_word,ngram):\n",
    "    # Returns the perplexity of the given sentence\n",
    "    # second formula from assignment pdf \n",
    "\n",
    "    \n",
    "    for p in poems:\n",
    "        result=1\n",
    "        print(p)\n",
    "        for pl in p.split(\"\\n\"):\n",
    "            result*=Sprob(pl,n_grams_dict,unique_word,ngram)\n",
    "        \n",
    "        result=1/result\n",
    "        result = result**(1/(len(p.split(\" \"))+satir))\n",
    "\n",
    "        print(\"\\t-> Perplexity of poem :{0:.20f}\\n########################\".format(result))\n",
    "\n",
    "perplexity(generated_poems,count_dict,unique_gram,ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit418366e376b14bef830f0db0b5287b85"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
